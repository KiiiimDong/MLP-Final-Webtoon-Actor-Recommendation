{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634e6506",
   "metadata": {},
   "source": [
    "## 설명\n",
    "- 해당 오토인코더는 Convolution 신경망과 Deep 신경망을 결합한 2D AutoEncoder이다.\n",
    "- 학습 데이터는 사람 얼굴 1만장, 웹툰 등장인물 얼굴 1만장이다.\n",
    "- 기대효과는 Convolution 신경망을 통한 피쳐추출과 Deep AutoEncoder 구조를 결합하여 특징 벡터를 보다 잘 추출하는데 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60900f47",
   "metadata": {},
   "source": [
    "## 1. 텐서플로우 메모리 관리\n",
    "- 텐서플로우의 경우에 사용가능한 메모리를 모두 독점하는 특징이 있기 때문에 stack 방식으로 메모리를 관리하여 필요한 메모리만큼 할당하는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66988dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 21:30:16.594332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 21:30:16.622433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 21:30:16.625145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34908cc",
   "metadata": {},
   "source": [
    "## 2. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c1e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, MaxPooling2D, Input, UpSampling2D\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1142066",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4df496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "human_image_datas = glob('./image_human/*.jpg')\n",
    "webtoon_image_datas = glob('./image_webtoon/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86ae5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10456, 27702)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 크기 확인\n",
    "len(human_image_datas), len(webtoon_image_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be801fb",
   "metadata": {},
   "source": [
    "## 4. 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85637676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc885e86bf4d6f9cce8a87964712c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c41a32440432cb087fd62dd7801d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321a11eaaec64f47b2d572b22f2a3328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_set = [human_image_datas, webtoon_image_datas[:10456]]\n",
    "X = []\n",
    "\n",
    "for data in tqdm(data_set):\n",
    "    for image_name in tqdm(data):\n",
    "        image = cv2.imread(image_name, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        X.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e340de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy 배열로 변경\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48b3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad21f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 와 test data로 나누기\n",
    "train_images, test_images = train_test_split(X, test_size=0.1, shuffle=True, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7f94df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18820, 64, 64, 3), (2092, 64, 64, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape 확인\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa2735",
   "metadata": {},
   "source": [
    "## 5. AutoEncoder 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a042c1",
   "metadata": {},
   "source": [
    "### 1) Parameters 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa2577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params 설정\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "latent_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16867b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 클래스 정의\n",
    "class AutoEncoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        # 인코더 정의\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(64, 64, 3)),\n",
    "            Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            MaxPooling2D((2, 2), padding='same'),\n",
    "            Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            MaxPooling2D((2, 2), padding='same'),\n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(latent_dim, activation='relu')\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Reshape((16, 16, 3)),\n",
    "            Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            UpSampling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "            UpSampling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "            Conv2D(3, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d85aa3",
   "metadata": {},
   "source": [
    "### 2) 모델 생성 및 컴파일\n",
    "- 모델의 loss 함수는 재구성 오류를 확인하기 위해 mse로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca35a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 컴파일\n",
    "model = AutoEncoder(latent_dim)\n",
    "model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['mse'])\n",
    "checkpointer = ModelCheckpoint(filepath='./2D_AutoEncoder_model/2D_AutoEncoder.ckpt', \n",
    "                               verbose=1, save_best_only=True, save_weights_only=True, monitor='val_mse', mode='min')\n",
    "earlystopping = EarlyStopping(monitor='val_mse', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1392d",
   "metadata": {},
   "source": [
    "## 6. AutoEncoder Model 학습\n",
    "- AutoEncoder Model의 학습에서 x값과 y값은 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3abdb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 21:43:53.039639: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 925040640 exceeds 10% of free system memory.\n",
      "2022-08-07 21:43:53.933202: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 925040640 exceeds 10% of free system memory.\n",
      "2022-08-07 21:43:54.851946: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 925040640 exceeds 10% of free system memory.\n",
      "2022-08-07 21:43:55.503599: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 925040640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 21:43:58.268774: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-08-07 21:44:00.074780: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - ETA: 0s - loss: 0.0502 - mse: 0.0502\n",
      "Epoch 00001: val_mse improved from inf to 0.02713, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 71s 211ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 2/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0259 - mse: 0.0259\n",
      "Epoch 00002: val_mse improved from 0.02713 to 0.02456, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 62s 212ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 3/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0232 - mse: 0.0232\n",
      "Epoch 00003: val_mse improved from 0.02456 to 0.02209, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 4/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0219 - mse: 0.0219\n",
      "Epoch 00004: val_mse improved from 0.02209 to 0.02119, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 5/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0212 - mse: 0.0212\n",
      "Epoch 00005: val_mse did not improve from 0.02119\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 6/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0207 - mse: 0.0207\n",
      "Epoch 00006: val_mse improved from 0.02119 to 0.02097, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 7/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0203 - mse: 0.0203\n",
      "Epoch 00007: val_mse improved from 0.02097 to 0.01953, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 00008: val_mse did not improve from 0.01953\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 9/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0193 - mse: 0.0193\n",
      "Epoch 00009: val_mse improved from 0.01953 to 0.01881, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 10/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 00010: val_mse improved from 0.01881 to 0.01879, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 11/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 00011: val_mse did not improve from 0.01879\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0185 - mse: 0.0185\n",
      "Epoch 00012: val_mse improved from 0.01879 to 0.01816, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 13/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0182 - mse: 0.0182\n",
      "Epoch 00013: val_mse did not improve from 0.01816\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 14/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0180 - mse: 0.0180\n",
      "Epoch 00014: val_mse did not improve from 0.01816\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 15/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 00015: val_mse improved from 0.01816 to 0.01769, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 16/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 00016: val_mse did not improve from 0.01769\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 17/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0177 - mse: 0.0177\n",
      "Epoch 00017: val_mse improved from 0.01769 to 0.01767, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 18/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 00018: val_mse did not improve from 0.01767\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 19/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0175 - mse: 0.0175\n",
      "Epoch 00019: val_mse improved from 0.01767 to 0.01750, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 20/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0174 - mse: 0.0174\n",
      "Epoch 00020: val_mse improved from 0.01750 to 0.01733, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 21/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 00021: val_mse improved from 0.01733 to 0.01733, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 22/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 00022: val_mse did not improve from 0.01733\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 23/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0172 - mse: 0.0172\n",
      "Epoch 00023: val_mse did not improve from 0.01733\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 24/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 00024: val_mse improved from 0.01733 to 0.01719, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 25/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 00025: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 26/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0171 - mse: 0.0171\n",
      "Epoch 00026: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 27/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 00027: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 28/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0168 - mse: 0.0168\n",
      "Epoch 00028: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 29/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 00029: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 30/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0167 - mse: 0.0167\n",
      "Epoch 00030: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 31/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 00031: val_mse did not improve from 0.01719\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 32/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 00032: val_mse improved from 0.01719 to 0.01703, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 33/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0166 - mse: 0.0166\n",
      "Epoch 00033: val_mse did not improve from 0.01703\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 34/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0165 - mse: 0.0165\n",
      "Epoch 00034: val_mse did not improve from 0.01703\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 35/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 00035: val_mse improved from 0.01703 to 0.01702, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 36/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 00036: val_mse did not improve from 0.01702\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 37/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 00037: val_mse did not improve from 0.01702\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 38/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 00038: val_mse improved from 0.01702 to 0.01696, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 39/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 00039: val_mse did not improve from 0.01696\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 40/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0162 - mse: 0.0162\n",
      "Epoch 00040: val_mse did not improve from 0.01696\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 41/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0163 - mse: 0.0163\n",
      "Epoch 00041: val_mse did not improve from 0.01696\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 42/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 00042: val_mse did not improve from 0.01696\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 43/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 00043: val_mse improved from 0.01696 to 0.01696, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 221ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 44/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0161 - mse: 0.0161\n",
      "Epoch 00044: val_mse did not improve from 0.01696\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 45/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 00045: val_mse improved from 0.01696 to 0.01695, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 46/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0159 - mse: 0.0159\n",
      "Epoch 00046: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 47/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 00047: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 48/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 00048: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 49/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0160 - mse: 0.0160\n",
      "Epoch 00049: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 50/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 00050: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 51/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 00051: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 52/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 00052: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 53/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0157 - mse: 0.0157\n",
      "Epoch 00053: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 54/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 00054: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 55/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 00055: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 56/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 00056: val_mse did not improve from 0.01695\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 57/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 00057: val_mse improved from 0.01695 to 0.01689, saving model to ./2D_AutoEncoder_model/2D_AutoEncoder.ckpt\n",
      "295/295 [==============================] - 65s 220ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 58/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0156 - mse: 0.0156\n",
      "Epoch 00058: val_mse did not improve from 0.01689\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 59/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 00059: val_mse did not improve from 0.01689\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 60/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0154 - mse: 0.0154\n",
      "Epoch 00060: val_mse did not improve from 0.01689\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 61/1000\n",
      "294/295 [============================>.] - ETA: 0s - loss: 0.0155 - mse: 0.0155\n",
      "Epoch 00061: val_mse did not improve from 0.01689\n",
      "295/295 [==============================] - 65s 219ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 62/1000\n",
      " 27/295 [=>............................] - ETA: 57s - loss: 0.0156 - mse: 0.0156"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_images,\n",
    "                epochs=epochs,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images, test_images), workers=3, callbacks=[checkpointer, earlystopping], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150320a",
   "metadata": {},
   "source": [
    "## 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db5dca",
   "metadata": {},
   "source": [
    "## 8. AutoEncoder 모델 테스트\n",
    "- 테스트 이미지의 오리지널과 인코딩 - 디코딩 후의 이미지를 시각적으로 확인\n",
    "    - 재구성이 잘된 경우 오리지널과 디코딩 이미지의 차이가 크지 않을 것이다.\n",
    "    - 즉, 차이가 크지 않다는 것은 latent vector가 이미지의 특징을 잘 추출했다는 것이므로 성공적인 모델이라고 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d5723",
   "metadata": {},
   "source": [
    "### 1) Best AutoEncoder 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = AutoEncoder(latent_dim)\n",
    "load_model.load_weights('./2D_AutoEncoder_model/2D_AutoEncoder.ckpt')\n",
    "load_model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['mse'])\n",
    "load_model.evaluate(test_images, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2563f2",
   "metadata": {},
   "source": [
    "### 2) 테스트 이미지를 통한 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9536afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = load_model.encoder(test_images[:100]).numpy()\n",
    "decoded_imgs = load_model.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7441d36",
   "metadata": {},
   "source": [
    "- 10장의 이미지를 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "plt.figure(figsize=(2 * 10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.title('original')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(2, n, i+1+n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title('reconstructed')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10576f",
   "metadata": {},
   "source": [
    "## 9. 이미지간 유사도 비교 테스트\n",
    "- 본 모델의 최종 목적은 latent 벡터를 통한 이미지 유사도 비교에 있기 때문에 이미지간 유사도 비교 테스트를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 함수 정의 : 모델의 입력 데이터에 맞게 이미지 데이터를 전처리한다. // cv2 형식의 데이터\n",
    "def image_preprocessing(img):\n",
    "    img = cv2.resize((64, 64))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fa04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교할 이미지 불러오기\n",
    "image_1 = cv2.imread('../version_1.0/image_data/Actor/')\n",
    "image_2 = cv2.imread('../version_1.0/image_data/Actor2Webtoon/')\n",
    "image_3 = cv2.imread('../version_1.0/image_data/Webtoon/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e472e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리\n",
    "conv_image_1 = image_preprocessing(image_1)\n",
    "conv_image_2 = image_preprocessing(image_2)\n",
    "conv_image_3 = image_preprocessing(image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 AutoEncoder의 encoder를 통해서 벡터화\n",
    "vec_image_1 = load_model.encoder(conv_image_1)\n",
    "vec_image_2 = load_model.encoder(conv_image_2)\n",
    "vec_image_3 = load_model.encoder(conv_image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db374d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 유사도 비교\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
